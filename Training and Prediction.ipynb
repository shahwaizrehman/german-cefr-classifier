{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee01db09-44e5-4bbe-be78-559169d57009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Loading my original data...\n",
      "→ My data: 1259 sentences\n",
      "\n",
      "Step 2: Adding public German CEFR datasets from Hugging Face...\n",
      "→ UniversalCEFR/elg_cefr_de: 509 sentences\n",
      "→ EliasAhl/german-cefr: 606 sentences\n",
      "\n",
      "Step 3: Merging all data and removing duplicates...\n",
      "→ Final dataset: 2273 unique sentences\n",
      "\n",
      "Step 4: Saving as cefr_final_merged.csv\n",
      "cefr_final_merged.csv has been created!\n",
      "You can now open it and see all 2273 sentences with CEFR levels\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "\n",
    "print(\"Step 1: Loading my original data...\")\n",
    "df_my = pd.read_csv(\"cefr_augmented.csv\", encoding='latin1')\n",
    "\n",
    "# Fix encoding issues\n",
    "df_my['text'] = df_my['text'].str.replace('Ã¼', 'ü').str.replace('Ã¤', 'ä')\\\n",
    "                             .str.replace('Ã¶', 'ö').str.replace('ÃŸ', 'ß')\n",
    "df_my['CEFR'] = df_my['CEFR'].replace({'C2': 'C1'})\n",
    "\n",
    "print(f\"→ My data: {len(df_my)} sentences\")\n",
    "\n",
    "print(\"\\nStep 2: Adding public German CEFR datasets from Hugging Face...\")\n",
    "\n",
    "# Public dataset 1\n",
    "df1 = load_dataset(\"UniversalCEFR/elg_cefr_de\", split=\"train\").to_pandas()\n",
    "df1 = df1[['text', 'cefr_level']].rename(columns={'cefr_level': 'CEFR'})\n",
    "print(f\"→ UniversalCEFR/elg_cefr_de: {len(df1)} sentences\")\n",
    "\n",
    "# Public dataset 2\n",
    "df2 = load_dataset(\"EliasAhl/german-cefr\", split=\"train\").to_pandas()\n",
    "df2 = df2[['text', 'cefrLevel']].rename(columns={'cefrLevel': 'CEFR'})\n",
    "print(f\"→ EliasAhl/german-cefr: {len(df2)} sentences\")\n",
    "\n",
    "# Clean C2 → C1 in both\n",
    "for df in [df1, df2]:\n",
    "    df['CEFR'] = df['CEFR'].replace({'C2': 'C1'})\n",
    "\n",
    "print(\"\\nStep 3: Merging all data and removing duplicates...\")\n",
    "final_df = pd.concat([df_my[['text', 'CEFR']], df1, df2], ignore_index=True)\n",
    "final_df = final_df.drop_duplicates(subset='text').dropna()\n",
    "\n",
    "print(f\"→ Final dataset: {len(final_df)} unique sentences\")\n",
    "\n",
    "print(\"\\nStep 4: Saving as cefr_final_merged.csv\")\n",
    "final_df.to_csv(\"cefr_final_merged.csv\", index=False)\n",
    "\n",
    "print(\"cefr_final_merged.csv has been created!\")\n",
    "print(\"You can now open it and see all 2273 sentences with CEFR levels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02945332-13cc-4a8d-a36e-69fb64a9243b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY: 0.7912\n",
      "Model saved!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# Load the merged data you already created (fast, no internet!)\n",
    "df = pd.read_csv(\"cefr_final_merged.csv\")\n",
    "\n",
    "labels = ['A1', 'A2', 'B1', 'B2', 'C1']\n",
    "df['label'] = df['CEFR'].map({l: i for i, l in enumerate(labels)})\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df['label'])\n",
    "\n",
    "# Best model for German CEFR\n",
    "vectorizer = TfidfVectorizer(analyzer='char_wb', ngram_range=(3,5), lowercase=False)\n",
    "X_train = vectorizer.fit_transform(train_df['text'])\n",
    "X_test  = vectorizer.transform(test_df['text'])\n",
    "y_train = train_df['label']\n",
    "y_test  = test_df['label']\n",
    "\n",
    "model = LinearSVC(C=1.0, class_weight='balanced', max_iter=1000, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(f\"ACCURACY: {accuracy_score(y_test, model.predict(X_test)):.4f}\")\n",
    "\n",
    "# Save (overwrite old weak model)\n",
    "os.makedirs(\"cefr_german_model\", exist_ok=True)\n",
    "joblib.dump(model,      \"cefr_german_model/model.pkl\")\n",
    "joblib.dump(vectorizer, \"cefr_german_model/vectorizer.pkl\")\n",
    "joblib.dump(labels,     \"cefr_german_model/labels.pkl\")\n",
    "print(\"Model saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef46409c-049e-4d70-8516-50f9a30a7712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a German sentence:  Ich denke, dass wir mehr für den Umweltschutz tun sollten.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CEFR Level: C1\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Load your perfect 79.1% model\n",
    "vectorizer = joblib.load(\"cefr_german_model/vectorizer.pkl\")\n",
    "model      = joblib.load(\"cefr_german_model/model.pkl\")\n",
    "labels     = ['A1', 'A2', 'B1', 'B2', 'C1']\n",
    "\n",
    "def cefr(sentence):\n",
    "    return labels[model.predict(vectorizer.transform([sentence]))[0]]\n",
    "\n",
    "# One sentence → one prediction → done\n",
    "sentence = input(\"Enter a German sentence: \").strip()\n",
    "\n",
    "if not sentence:\n",
    "    print(\"No input — goodbye!\")\n",
    "else:\n",
    "    level = cefr(sentence)\n",
    "    print(f\"\\nCEFR Level: {level}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6ea52c-610e-45e2-8a01-35b74765bf41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
